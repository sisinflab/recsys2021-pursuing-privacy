{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "TBA: Neural Collaborative Filtering in Securely Aggregated Vertical Federated Learning with SMPC\n",
    "\n",
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!conda install pandas\n",
    "!conda install pytorch-cpu -c pytorch -y\n",
    "!conda install \"syft @ git+https://github.com/OpenMined/PySyft@sympc-dev#egg=syft&subdirectory=packages/syft\"\n",
    "!conda install -e \"git+https://github.com/OpenMined/SyMPC#egg=sympc\"\n",
    "\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import io\n",
    "import copy\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import syft as sy\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "from torchfm.layer import FeaturesEmbedding, MultiLayerPerceptron\n",
    "from collections import OrderedDict\n",
    "from utils import split_data\n",
    "from neural_collaborative_filtering import NeuralCollaborativeFiltering\n",
    "from movielens_dataset import MovieLensDataset\n",
    "\n",
    "# pip3 install \"syft @ git+https://github.com/OpenMined/PySyft@sympc-dev#egg=syft&subdirectory=packages/syft\"\n",
    "# pip3 install -e \"git+https://github.com/OpenMined/SyMPC#egg=sympc\"\n",
    "\n",
    "from sympc.session import Session\n",
    "from sympc.session import SessionManager\n",
    "from sympc.tensor import MPCTensor\n",
    "\n",
    "# The MPCTensor is the tensor that holds reference to the shares owned by the different parties.\n",
    "\n",
    "\n",
    "np.random.seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load and processing Data\n",
    "\n",
    "We handle the latest version of the Movielens Small dataset. We prepare the trainig/test splitting.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/movielens/dataset.csv')\n",
    "df['userId'] = df['userId'].map({v: k for k, v in enumerate(df['userId'].unique())})\n",
    "df['movieId'] = df['movieId'].map({v: k for k, v in enumerate(df['movieId'].unique())})\n",
    "data = split_data(df, 3)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_data_loaders = []\n",
    "valid_data_loaders = []\n",
    "test_data_loaders = []\n",
    "users = set()\n",
    "items = set()\n",
    "for i in range(len(data)):\n",
    "    train_length = int(len(data[i]) * 0.8)\n",
    "    valid_length = int(len(data[i]) * 0.1)\n",
    "    test_length = len(data[i]) - train_length - valid_length\n",
    "    local_dataset = MovieLensDataset(data[i])\n",
    "    train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(\n",
    "        local_dataset, (train_length, valid_length, test_length))\n",
    "    train_data_loaders.append(DataLoader(train_dataset, batch_size=batch_size, num_workers=0))\n",
    "    valid_data_loaders.append(DataLoader(valid_dataset, batch_size=batch_size, num_workers=0))\n",
    "    test_data_loaders.append(DataLoader(test_dataset, batch_size=batch_size, num_workers=0))\n",
    "    users = users.union(set(np.unique(train_dataset.dataset.items[:, 0])))\n",
    "    items = items.union(set(np.unique(train_dataset.dataset.items[:, 1])))\n",
    "n_users = len(users)\n",
    "n_items = len(items)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create the partis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# We have three organizations, let's create their virtual machines\n",
    "\n",
    "store1_vm = sy.VirtualMachine(name=\"store1\")\n",
    "store2_vm = sy.VirtualMachine(name=\"store2\")\n",
    "store3_vm = sy.VirtualMachine(name=\"store3\")\n",
    "\n",
    "# Get clients from each VM\n",
    "store1 = store1_vm.get_root_client()\n",
    "store2 = store2_vm.get_root_client()\n",
    "store3 = store3_vm.get_root_client()\n",
    "\n",
    "parties = [store1, store2, store3]\n",
    "\n",
    "session = Session(parties=parties)\n",
    "\n",
    "# When we do not pass any protocol to session, SyMPC uses SPDZ protocol with semi-honest security type.\n",
    "# SPDZ is used for multiplication and related operations (convolution,matmul,etc) and could extend to N parties.\n",
    "\n",
    "# Falcon can also provide a malicious security guarantee for an honest majority at the cost of higher inference time.\n",
    "# Malicious security ensures that all the parties compute according to the protocol\n",
    "# and do not deviate from protocol or tamper with shares.\n",
    "#\n",
    "\n",
    "SessionManager.setup_mpc(session)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Initialize the global model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ncf = NeuralCollaborativeFiltering(field_dims=(n_users, n_items), embed_dim=64, mlp_dims=(64, 32, 16), dropout=0.2,\n",
    "                                   user_field_idx=[0],\n",
    "                                   item_field_idx=[1])\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(params=ncf.parameters(), lr=0.01)\n",
    "\n",
    "def train(model, optimizer, data_loader, criterion, device, log_interval=100):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    tk0 = tqdm.tqdm(data_loader, smoothing=0, mininterval=1.0)\n",
    "    for i, (fields, target) in enumerate(tk0):\n",
    "        # fields, target = fields.to(device), target.to(device)\n",
    "        y = model(fields)\n",
    "        loss = criterion(y, target.float())\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if (i + 1) % log_interval == 0:\n",
    "            tk0.set_postfix(loss=total_loss / log_interval)\n",
    "            total_loss = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train the model in unsecure way"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rounds = 10\n",
    "local_epochs = 1\n",
    "\n",
    "for round in range(rounds):\n",
    "    print('***\\nRound', round + 1)\n",
    "    local_params = []\n",
    "    for u in range(len(data)):\n",
    "        # Local training of the model\n",
    "        print('Organization #', u + 1)\n",
    "        local_ncf = NeuralCollaborativeFiltering(field_dims=(n_users, n_items), embed_dim=64, mlp_dims=(64, 32, 16),\n",
    "                                           dropout=0.2,\n",
    "                                           user_field_idx=[0],\n",
    "                                           item_field_idx=[1])\n",
    "        local_ncf.load_state_dict(copy.deepcopy(ncf.state_dict()))\n",
    "\n",
    "        for i in range(local_epochs):\n",
    "            print('Local epoch', i + 1)\n",
    "            # copy the model\n",
    "            train(local_ncf, optimizer, train_data_loaders[u], criterion, 'cpu')\n",
    "        # The parameters in local_params are the secrets of each client\n",
    "        local_params.append({param: value for param, value in local_ncf.state_dict().items()})\n",
    "    print(\"Computing the mean...\")\n",
    "    global_params = {\n",
    "        name: torch.mean(torch.stack([local_params[i][name].float() for i in range(len(local_params))]), dim=0) for\n",
    "        name in local_params[0]}\n",
    "\n",
    "    # Set the global model with the new computed parameters\n",
    "    with torch.no_grad():\n",
    "        print(\"Updating the global model...\")\n",
    "        ncf.load_state_dict(OrderedDict(global_params))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Initialize the global model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ncf = NeuralCollaborativeFiltering(field_dims=(n_users, n_items), embed_dim=64, mlp_dims=(64, 32, 16), dropout=0.2,\n",
    "                                   user_field_idx=[0],\n",
    "                                   item_field_idx=[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train the model in secure way"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rounds = 10\n",
    "local_epochs = 1\n",
    "\n",
    "for round in range(rounds):\n",
    "    print('***\\nRound', round + 1)\n",
    "    local_params = []\n",
    "    for u in range(len(data)):\n",
    "        # Local training of the model\n",
    "        print('Organization #', u + 1)\n",
    "        local_ncf = NeuralCollaborativeFiltering(field_dims=(n_users, n_items), embed_dim=64, mlp_dims=(64, 32, 16),\n",
    "                                           dropout=0.2,\n",
    "                                           user_field_idx=[0],\n",
    "                                           item_field_idx=[1])\n",
    "        local_ncf.load_state_dict(copy.deepcopy(ncf.state_dict()))\n",
    "\n",
    "        for i in range(local_epochs):\n",
    "            print('Local epoch', i + 1)\n",
    "            # copy the model\n",
    "            train(local_ncf, optimizer, train_data_loaders[u], criterion, 'cpu')\n",
    "        # The parameters in local_params are the secrets of each client\n",
    "        local_params.append({param: value for param, value in local_ncf.state_dict().items()})\n",
    "    # Now, we should compute the mean of the local parameters with SMPC\n",
    "    # 1. Each party \"shares\" its secret with the other parties in a secure fashion\n",
    "    print(\"Creating the shares...\")\n",
    "    secret_local_params = []\n",
    "    for u in local_params:\n",
    "        secret_local_params.append(\n",
    "            {param: value.share(session=session) if not param.endswith('num_batches_tracked') else value for\n",
    "             param, value in u.items()})\n",
    "    # 2. We can compute the secret mean\n",
    "    print(\"Computing the secret mean...\")\n",
    "    secret_global_params = {name: sum([secret_local_params[i][name] for i in range(len(secret_local_params))]) / len(\n",
    "        secret_local_params) if not name.endswith('num_batches_tracked') else sum(\n",
    "        [secret_local_params[i][name] for i in range(len(secret_local_params))]) for name in secret_local_params[0]}\n",
    "\n",
    "    # Finally, we can reconstruct the real value of the mean\n",
    "    print(\"Reconstructing the mean...\")\n",
    "    global_params = {name: value.reconstruct() if not name.endswith('num_batches_tracked') else value for name, value in\n",
    "                     secret_global_params.items()}\n",
    "\n",
    "    # Set the global model with the new computed parameters\n",
    "    with torch.no_grad():\n",
    "        print(\"Updating the global model...\")\n",
    "        ncf.load_state_dict(OrderedDict(global_params))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}