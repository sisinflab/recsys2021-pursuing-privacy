{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "TBA: Differentially Private Neural Collaborative Filtering with TF Privacy\n",
    "\n",
    "In this notebook, we will learn to exploit **tf-privacy** to train a simple recommendation model\n",
    "using a DP version of GradientDescentOptimizer.\n",
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!conda install pandas tqdm tensorflow\n",
    "\n",
    "import gflags\n",
    "import itertools\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "import io\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow_privacy.privacy.analysis.gdp_accountant import compute_eps_poisson\n",
    "from tensorflow_privacy.privacy.analysis.gdp_accountant import compute_mu_poisson\n",
    "from tensorflow_privacy.privacy.optimizers import dp_optimizer\n",
    "\n",
    "from utils import splitting\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(3)\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "FLAGS = gflags.FLAGS\n",
    "gflags.DEFINE_boolean(\n",
    "    'dpsgd', False, 'If True, train with DP-SGD. If False, '\n",
    "                   'train with vanilla SGD.')\n",
    "gflags.DEFINE_float('learning_rate', .05, 'Learning rate for training')\n",
    "\n",
    "argv = FLAGS(sys.argv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load and processing Data\n",
    "\n",
    "We handle the latest version of the Movielens Small dataset. We prepare the trainig/test splitting.\n",
    "We provided also the complete pairs of user/item to evaluate."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "        'data/movielens/dataset.csv')\n",
    "data = data.astype('int')\n",
    "n_users = len(set(data['userId']))\n",
    "n_movies = len(set(data['movieId']))\n",
    "print('number of movie: ', n_movies)\n",
    "print('number of user: ', n_users)\n",
    "\n",
    "print('number of ratings:', data.shape[0])\n",
    "print('percentage of sparsity:',\n",
    "      (1 - data.shape[0] / n_users / n_movies) * 100, '%')\n",
    "\n",
    "train, test = splitting(data, ratio=0.2)\n",
    "\n",
    "test = test[test['movieId'].isin(train['movieId'].unique())]\n",
    "\n",
    "user_map = {v: k for k, v in enumerate(train['userId'].unique())}\n",
    "movie_map = {v: k for k, v in enumerate(train['movieId'].unique())}\n",
    "\n",
    "train['userId'] = train['userId'].map(user_map)\n",
    "train['movieId'] = train['movieId'].map(movie_map)\n",
    "\n",
    "test['userId'] = test['userId'].map(user_map)\n",
    "test['movieId'] = test['movieId'].map(movie_map)\n",
    "\n",
    "train_data, test_data, _ = train.values, test.values, np.mean(train['rating'])\n",
    "\n",
    "full_eval = pd.DataFrame(list(itertools.product(set(test_data[:, 0]), set(train_data[:, 1]))))\n",
    "\n",
    "train_item_filter = full_eval.groupby([0]) \\\n",
    "    .apply(lambda x: x[1].isin(train_data[train_data[:, 0] == x[0].unique()][:, 1])).reset_index(drop=True)\n",
    "\n",
    "full_eval = full_eval[~train_item_filter]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define the model\n",
    "\n",
    "Create a basic Neural Matrix Factorization model. The final formulation is divided into two parts:\n",
    "* GMF part is a simple element-wise multiplication between user and item embedding\n",
    "* MLP part in this simple case is only a concatenation of two latent feature (user and item)\n",
    "* the final layer is a concatenation between the output of GMF and MLP before the sigmoid activation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sampling_batch = 10000\n",
    "microbatches = 10000\n",
    "num_examples = 80419\n",
    "\n",
    "def nn_model_fn(features, labels, mode):\n",
    "\n",
    "    n_latent_factors_user = 64\n",
    "    n_latent_factors_movie = 64\n",
    "    n_latent_factors_mf = 64\n",
    "\n",
    "    user_input = tf.reshape(features['user'], [-1, 1])\n",
    "    item_input = tf.reshape(features['movie'], [-1, 1])\n",
    "\n",
    "    # number of users: 610; number of movies: 9724\n",
    "    mf_embedding_user = tf.keras.layers.Embedding(\n",
    "        610, n_latent_factors_mf, input_length=1, embeddings_initializer=tf.initializers.GlorotUniform())\n",
    "    mf_embedding_item = tf.keras.layers.Embedding(\n",
    "        8983, n_latent_factors_mf, input_length=1, embeddings_initializer=tf.initializers.GlorotUniform())\n",
    "    mlp_embedding_user = tf.keras.layers.Embedding(\n",
    "        610, n_latent_factors_user, input_length=1, embeddings_initializer=tf.initializers.GlorotUniform())\n",
    "    mlp_embedding_item = tf.keras.layers.Embedding(\n",
    "        8983, n_latent_factors_movie, input_length=1, embeddings_initializer=tf.initializers.GlorotUniform())\n",
    "\n",
    "    mf_embedding_user(0)\n",
    "    mf_embedding_item(0)\n",
    "    mlp_embedding_user(0)\n",
    "    mlp_embedding_item(0)\n",
    "\n",
    "    # GMF part\n",
    "    # Flatten the embedding vector as latent features in GMF\n",
    "    mf_user_latent = tf.keras.layers.Flatten()(mf_embedding_user(user_input))\n",
    "    mf_item_latent = tf.keras.layers.Flatten()(mf_embedding_item(item_input))\n",
    "    # Element-wise multiply\n",
    "    mf_vector = tf.keras.layers.multiply([mf_user_latent, mf_item_latent])\n",
    "\n",
    "    # MLP part\n",
    "    # Flatten the embedding vector as latent features in MLP\n",
    "    mlp_user_latent = tf.keras.layers.Flatten()(mlp_embedding_user(user_input))\n",
    "    mlp_item_latent = tf.keras.layers.Flatten()(mlp_embedding_item(item_input))\n",
    "    # Concatenation of two latent features\n",
    "    mlp_vector = tf.keras.layers.concatenate([mlp_user_latent, mlp_item_latent])\n",
    "\n",
    "    predict_vector = tf.keras.layers.concatenate([mf_vector, mlp_vector])\n",
    "\n",
    "    logits = tf.keras.layers.Dense(1)(predict_vector)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'score': tf.nn.sigmoid(logits)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate loss as a vector (to support microbatches in DP-SGD).\n",
    "    vector_loss = tf.keras.losses.BinaryCrossentropy(reduction=tf.losses.Reduction.NONE, from_logits=True)(\n",
    "        tf.expand_dims(labels, -1), logits)\n",
    "    # Define mean of loss across minibatch (for reporting through tf.Estimator).\n",
    "    scalar_loss = tf.reduce_mean(vector_loss)\n",
    "\n",
    "    # Configure the training op (for TRAIN mode).\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        if FLAGS.dpsgd:\n",
    "            # Use DP version of GradientDescentOptimizer. Other optimizers are\n",
    "            # available in dp_optimizer. Most optimizers inheriting from\n",
    "            # tf.train.Optimizer should be wrappable in differentially private\n",
    "            # counterparts by calling dp_optimizer.optimizer_from_args().\n",
    "            optimizer = dp_optimizer.DPAdamGaussianOptimizer(\n",
    "                l2_norm_clip=FLAGS.l2_norm_clip,\n",
    "                noise_multiplier=FLAGS.noise_multiplier,\n",
    "                num_microbatches=microbatches,\n",
    "                learning_rate=FLAGS.learning_rate)\n",
    "            opt_loss = vector_loss\n",
    "        else:\n",
    "            optimizer = tf.compat.v1.train.AdamOptimizer(\n",
    "                learning_rate=FLAGS.learning_rate)\n",
    "            opt_loss = scalar_loss\n",
    "\n",
    "        global_step = tf.compat.v1.train.get_global_step()\n",
    "        train_op = optimizer.minimize(loss=opt_loss, global_step=global_step)\n",
    "        # In the following, we pass the mean of the loss (scalar_loss) rather than\n",
    "        # the vector_loss because tf.estimator requires a scalar loss. This is only\n",
    "        # used for evaluation and debugging by tf.estimator. The actual loss being\n",
    "        # minimized is opt_loss defined above and passed to optimizer.minimize().\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, loss=scalar_loss, train_op=train_op)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ml_classifier = tf.estimator.Estimator(model_fn=nn_model_fn, model_dir=FLAGS.model_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create the full evaluation set input function\n",
    "\n",
    "We prepare the evaluation input function which is fed into our model to get the final recommendation lists\n",
    "for each user."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "        x={\n",
    "            'user': full_eval[0].values,\n",
    "            'movie': full_eval[1].values\n",
    "        },\n",
    "        num_epochs=1,\n",
    "        batch_size=len(full_eval),\n",
    "        shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the model\n",
    "\n",
    "We start to train the model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "steps_per_epoch = num_examples // sampling_batch\n",
    "test_accuracy_list = []\n",
    "for epoch in range(1, FLAGS.epochs + 1):\n",
    "    for _ in range(steps_per_epoch):\n",
    "        whether = np.random.random_sample(num_examples) > (\n",
    "                1 - sampling_batch / num_examples)\n",
    "        subsampling = [i for i in np.arange(num_examples) if whether[i]]\n",
    "        microbatches = len(subsampling)\n",
    "\n",
    "        train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "            x={\n",
    "                'user': train_data[subsampling, 0],\n",
    "                'movie': train_data[subsampling, 1]\n",
    "            },\n",
    "            y=(train_data[subsampling, 2] >= 4).astype(np.float32),\n",
    "            batch_size=len(subsampling),\n",
    "            num_epochs=1,\n",
    "            shuffle=False)\n",
    "        # Train the model for one step.\n",
    "        ml_classifier.train(input_fn=train_input_fn, steps=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate the model\n",
    "\n",
    "Exploiting the trained model we compute the final recommendation list user by user and evaluate three different metrics:\n",
    "* HR@10\n",
    "* Prec@10\n",
    "* Rec@10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = ml_classifier.predict(input_fn=eval_input_fn, yield_single_examples=False)\n",
    "\n",
    "for results in score:\n",
    "    full_eval[2] = results['score']\n",
    "    prediction = full_eval.sort_values([0, 2], ascending=[True, False])\n",
    "\n",
    "hrs = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for u in prediction[0].unique():\n",
    "    top_k = prediction[prediction[0] == u][1][:10]\n",
    "    relevant_user_items = test_data[np.logical_and(test_data[:, 0] == u, test_data[:, 2] >= 4)][:, 1]\n",
    "    n_rel_and_rec_k = sum(i in relevant_user_items for i in top_k)\n",
    "    hrs.append(n_rel_and_rec_k)\n",
    "    precisions.append(n_rel_and_rec_k / 10)\n",
    "    try:\n",
    "        recalls.append(n_rel_and_rec_k / len(relevant_user_items))\n",
    "    except ZeroDivisionError:\n",
    "        recalls.append(0)\n",
    "hr = sum(hrs) / len(hrs)\n",
    "precision = sum(precisions) / len(precisions)\n",
    "recall = sum(recalls) / len(recalls)\n",
    "\n",
    "print(f\"HR@10: {hr}\")\n",
    "print(f\"Precision@10: {precision}\")\n",
    "print(f\"Recall@10: {recall}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Retrain the model with DP strategy\n",
    "\n",
    "Now we train one more time the model, but now we use DP mechanism as learning strategy."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gflags.DEFINE_boolean(\n",
    "    'dpsgd', True, 'If True, train with DP-SGD. If False, '\n",
    "                   'train with vanilla SGD.')\n",
    "gflags.DEFINE_float('learning_rate', .05, 'Learning rate for training')\n",
    "gflags.DEFINE_float('noise_multiplier', 0.55,\n",
    "                    'Ratio of the standard deviation to the clipping norm')\n",
    "gflags.DEFINE_float('l2_norm_clip', 5, 'Clipping norm')\n",
    "gflags.DEFINE_integer('epochs', 15, 'Number of epochs')\n",
    "gflags.DEFINE_integer('max_mu', 3, 'GDP upper limit')\n",
    "gflags.DEFINE_string('model_dir', None, 'Model directory')\n",
    "argv = FLAGS(sys.argv)\n",
    "\n",
    "ml_classifier = tf.estimator.Estimator(model_fn=nn_model_fn, model_dir=FLAGS.model_dir)\n",
    "\n",
    "steps_per_epoch = num_examples // sampling_batch\n",
    "test_accuracy_list = []\n",
    "for epoch in range(1, FLAGS.epochs + 1):\n",
    "    for _ in range(steps_per_epoch):\n",
    "        whether = np.random.random_sample(num_examples) > (\n",
    "                1 - sampling_batch / num_examples)\n",
    "        subsampling = [i for i in np.arange(num_examples) if whether[i]]\n",
    "        microbatches = len(subsampling)\n",
    "\n",
    "        train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "            x={\n",
    "                'user': train_data[subsampling, 0],\n",
    "                'movie': train_data[subsampling, 1]\n",
    "            },\n",
    "            y=(train_data[subsampling, 2] >= 4).astype(np.float32),\n",
    "            batch_size=len(subsampling),\n",
    "            num_epochs=1,\n",
    "            shuffle=False)\n",
    "        # Train the model for one step.\n",
    "        ml_classifier.train(input_fn=train_input_fn, steps=1)\n",
    "\n",
    "    # Compute the privacy budget expended so far.\n",
    "    if FLAGS.dpsgd:\n",
    "        eps = compute_eps_poisson(epoch, FLAGS.noise_multiplier, num_examples,\n",
    "                                  sampling_batch, 1e-6)\n",
    "        mu = compute_mu_poisson(epoch, FLAGS.noise_multiplier, num_examples,\n",
    "                                sampling_batch)\n",
    "        print('For delta=1e-6, the current epsilon is: %.2f' % eps)\n",
    "        print('For delta=1e-6, the current mu is: %.2f' % mu)\n",
    "\n",
    "        if mu > FLAGS.max_mu:\n",
    "            break\n",
    "    else:\n",
    "        print('Trained with vanilla non-private SGD optimizer')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate the performance\n",
    "\n",
    "Exploiting the new trained model we compute the final recommendation list user by user and evaluate three different metrics:\n",
    "* HR@10\n",
    "* Prec@10\n",
    "* Rec@10\n",
    "\n",
    "We compare these results w.r.t. the other obtained with non-private optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "score = ml_classifier.predict(input_fn=eval_input_fn, yield_single_examples=False)\n",
    "\n",
    "for results in score:\n",
    "    full_eval[2] = results['score']\n",
    "    prediction = full_eval.sort_values([0, 2], ascending=[True, False])\n",
    "\n",
    "hrs = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for u in prediction[0].unique():\n",
    "    top_k = prediction[prediction[0] == u][1][:10]\n",
    "    relevant_user_items = test_data[np.logical_and(test_data[:, 0] == u, test_data[:, 2] >= 4)][:, 1]\n",
    "    n_rel_and_rec_k = sum(i in relevant_user_items for i in top_k)\n",
    "    hrs.append(n_rel_and_rec_k)\n",
    "    precisions.append(n_rel_and_rec_k / 10)\n",
    "    try:\n",
    "        recalls.append(n_rel_and_rec_k / len(relevant_user_items))\n",
    "    except ZeroDivisionError:\n",
    "        recalls.append(0)\n",
    "hr = sum(hrs) / len(hrs)\n",
    "precision = sum(precisions) / len(precisions)\n",
    "recall = sum(recalls) / len(recalls)\n",
    "\n",
    "print(f\"HR@10: {hr}\")\n",
    "print(f\"Precision@10: {precision}\")\n",
    "print(f\"Recall@10: {recall}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}