{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook, we will learn to implement a simple differentially private matrix factorization from scratch, with three different strategies:\n",
    "* input perturbation with Laplacian mechanism\n",
    "* gradient perturbation with Laplacian mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/claudio/PycharmProjects/RecSysPrivacyTutorial/venv/lib/python3.6/site-packages (1.1.5)\r\n",
      "Requirement already satisfied: tqdm in /home/claudio/PycharmProjects/RecSysPrivacyTutorial/venv/lib/python3.6/site-packages (4.62.2)\r\n",
      "Collecting matplotlib\r\n",
      "  Using cached matplotlib-3.3.4-cp36-cp36m-manylinux1_x86_64.whl (11.5 MB)\r\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/claudio/PycharmProjects/RecSysPrivacyTutorial/venv/lib/python3.6/site-packages (from pandas) (1.19.5)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/claudio/PycharmProjects/RecSysPrivacyTutorial/venv/lib/python3.6/site-packages (from pandas) (2021.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/claudio/PycharmProjects/RecSysPrivacyTutorial/venv/lib/python3.6/site-packages (from pandas) (2.8.2)\r\n",
      "Collecting pillow>=6.2.0\r\n",
      "  Downloading Pillow-8.3.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 3.0 MB 8.4 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting kiwisolver>=1.0.1\r\n",
      "  Using cached kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\r\n",
      "Collecting cycler>=0.10\r\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/claudio/PycharmProjects/RecSysPrivacyTutorial/venv/lib/python3.6/site-packages (from matplotlib) (2.4.7)\r\n",
      "Requirement already satisfied: six in /home/claudio/PycharmProjects/RecSysPrivacyTutorial/venv/lib/python3.6/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\r\n",
      "Installing collected packages: pillow, kiwisolver, cycler, matplotlib\r\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.3.4 pillow-8.3.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas tqdm matplotlib\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import io\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "from utils import create_maps, splitting\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Load Data\n",
    "\n",
    "First, we download the latest version of the Movielens Small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Movielens Small from : https://files.grouplens.org/datasets/movielens/ml-latest-small.zip ...\n",
      "Extracting ratings...\n",
      "Printing ratings to data/movielens/ ...\n"
     ]
    }
   ],
   "source": [
    "url = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "print(f\"Getting Movielens Small from : {url} ...\")\n",
    "response = requests.get(url)\n",
    "\n",
    "ml_ratings = []\n",
    "\n",
    "print(\"Extracting ratings...\")\n",
    "with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
    "    for line in zip_ref.open(\"ml-latest-small/ratings.csv\"):\n",
    "        ml_ratings.append(str(line, \"utf-8\"))\n",
    "\n",
    "print(\"Printing ratings to data/movielens/ ...\")\n",
    "os.makedirs(\"data/movielens\", exist_ok=True)\n",
    "with open(\"data/movielens/dataset.csv\", \"w\") as f:\n",
    "    f.writelines(ml_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing splitting...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataframe_ml_small = pd.read_csv('data/movielens/dataset.csv')\n",
    "\n",
    "train_set, test_set = splitting(dataframe_ml_small)\n",
    "train_set = train_set.loc[:, ['userId', 'movieId', 'rating']]\n",
    "test_set = test_set.loc[:, ['userId', 'movieId', 'rating']]\n",
    "maps = create_maps(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "\n",
    "Create MF class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MF:\n",
    "    def __init__(self, dataset, maps, n_factors, relevance=3.5, i_avg=None, u_avg=None):\n",
    "        \"\"\"\n",
    "        :param dataset: interaction dataset should be a Pandas dataframe with three columns for user, item, and rating\n",
    "        :param n_factors:\n",
    "        \"\"\"\n",
    "        print(\"Building model...\")\n",
    "        self.ext2int_user_map, self.int2ext_user_map, self.ext2int_item_map, self.int2ext_item_map = maps\n",
    "        self.dataset = self.format_dataset(dataset)\n",
    "        self.rated_items = {\n",
    "            self.ext2int_user_map[u]: dataset[(dataset.iloc[:, 0] == u) & (dataset.iloc[:, 2] >= relevance)].iloc[:,\n",
    "                                      1].map(self.ext2int_item_map).astype(int).to_list() for u in\n",
    "            self.ext2int_user_map}\n",
    "        n_users = len(self.ext2int_user_map)\n",
    "        n_items = len(self.ext2int_item_map)\n",
    "        self.n_interactions = len(dataset)\n",
    "        self.delta_ratings = dataset.iloc[:, 2].max() - dataset.iloc[:, 2].min()\n",
    "        self.p = np.random.normal(size=(n_users, n_factors), scale=1./n_factors, loc=0)\n",
    "        self.q = np.random.normal(size=(n_items, n_factors), scale=1./n_factors, loc=0)\n",
    "\n",
    "        self.b_u = np.zeros(n_users)\n",
    "        self.b_i = np.zeros(n_items)\n",
    "        self.b = np.mean(dataset['rating'])\n",
    "\n",
    "        self.i_avg = None\n",
    "        self.u_avg = None\n",
    "        if i_avg is not None and u_avg is not None:\n",
    "            self.i_avg = i_avg.to_numpy()\n",
    "            self.u_avg = u_avg.to_numpy()\n",
    "\n",
    "    def format_dataset(self, df):\n",
    "        dataset = {}\n",
    "        dataset['userId'] = df.iloc[:, 0].map(self.ext2int_user_map).to_dict()\n",
    "        dataset['itemId'] = df.iloc[:, 1].map(self.ext2int_item_map).to_dict()\n",
    "        dataset['rating'] = df.iloc[:, 2].to_dict()\n",
    "        return dataset\n",
    "\n",
    "    def train(self, lr, beta, epochs):\n",
    "        print(\"Starting training...\")\n",
    "        for e in range(epochs):\n",
    "            print(f\"*** Epoch {e + 1}/{epochs} ***\")\n",
    "            for i in tqdm(range(self.n_interactions)):\n",
    "                p_u = self.p[self.dataset['userId'][i]]\n",
    "                q_i = self.q[self.dataset['itemId'][i]]\n",
    "                pred = self.b + self.b_u[self.dataset['userId'][i]] + self.b_i[self.dataset['itemId'][i]] + p_u.dot(q_i)\n",
    "                err = self.dataset['rating'][i] - pred\n",
    "\n",
    "                # Update biases\n",
    "                self.b_u[self.dataset['userId'][i]] += lr * (err - beta * self.b_u[self.dataset['userId'][i]])\n",
    "                self.b_i[self.dataset['itemId'][i]] += lr * (err - beta * self.b_i[self.dataset['itemId'][i]])\n",
    "\n",
    "                # Update embeddings\n",
    "                self.p[self.dataset['userId'][i]] = p_u + lr * (err * q_i - beta * p_u)\n",
    "                self.q[self.dataset['itemId'][i]] = q_i + lr * (err * p_u - beta * q_i)\n",
    "\n",
    "    def train_laplace_dp(self, lr, beta, epochs, eps, err_max=None):\n",
    "        for e in range(epochs):\n",
    "            print(f\"*** Epoch {e + 1}/{epochs} ***\")\n",
    "            for i in tqdm(range(self.n_interactions)):\n",
    "                p_u = self.p[self.dataset['userId'][i]]\n",
    "                q_i = self.q[self.dataset['itemId'][i]]\n",
    "                pred = self.b + self.b_u[self.dataset['userId'][i]] + self.b_i[self.dataset['itemId'][i]] + p_u.dot(q_i)\n",
    "\n",
    "                # We should add Laplacian noise scaled based on the sensitivity of the error\n",
    "                # Having two datasets A and B differing by the value of just one rating r_ui (namely r_ui(A) and r_ui(B)), we have that\n",
    "                # max |e(A) - e(B)| = max |(r_ui(A) - p_u * q_i) - (r_ui(B) - p_u * q_i)| = max |r_ui(A) - r_ui(B)| = delta_ratings\n",
    "                # For the composability theorem, we have to split the privacy budget by the number of epochs\n",
    "                err = self.dataset['rating'][i] - pred + np.random.laplace(scale=(epochs * self.delta_ratings / eps))\n",
    "\n",
    "                # Optionally we can constrain the error the limit the effect of the noise\n",
    "                if err_max:\n",
    "                    err = np.clip(err, -err_max, err_max)\n",
    "\n",
    "                # Update biases\n",
    "                self.b_u[self.dataset['userId'][i]] += lr * (err - beta * self.b_u[self.dataset['userId'][i]])\n",
    "                self.b_i[self.dataset['itemId'][i]] += lr * (err - beta * self.b_i[self.dataset['itemId'][i]])\n",
    "\n",
    "                self.p[self.dataset['userId'][i]] = p_u + lr * (err * q_i)\n",
    "                self.q[self.dataset['itemId'][i]] = q_i + lr * (err * p_u)\n",
    "\n",
    "\n",
    "    def evaluate(self, test=None, cutoff=10, relevance=0.5):\n",
    "        print(\"Starting evaluation...\")\n",
    "        if self.i_avg is not None and self.u_avg is not None:\n",
    "            prediction = self.b + self.b_u[:, np.newaxis] + self.b_i[np.newaxis, :] + \\\n",
    "                         (np.dot(self.p, self.q.T).T + self.i_avg[:, None]).T + self.u_avg[:, None]\n",
    "        else:\n",
    "            prediction = self.b + self.b_u[:, np.newaxis] + self.b_i[np.newaxis, :] + np.dot(self.p, self.q.T)\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        print(\"Reading test set...\")\n",
    "        relevant_items_test = {\n",
    "            self.ext2int_user_map[u]: set(test[(test.iloc[:, 0] == u) & (test.iloc[:, 2] >= relevance)].iloc[:, 1].map(\n",
    "                self.ext2int_item_map).dropna().astype(int).to_list()) for u in self.ext2int_user_map}\n",
    "        print(\"Computing metrics...\")\n",
    "        for u in self.int2ext_user_map:\n",
    "            prediction[u, self.rated_items[u]] = - np.inf\n",
    "            unordered_top_k = np.argpartition(prediction[u], -cutoff)[-cutoff:]\n",
    "            top_k = unordered_top_k[np.argsort(prediction[u][unordered_top_k])][::-1]\n",
    "            n_rel_and_rec_k = sum(i in relevant_items_test[u] for i in top_k)\n",
    "            precisions.append(n_rel_and_rec_k / cutoff)\n",
    "            try:\n",
    "                recalls.append(n_rel_and_rec_k / len(relevant_items_test[u]))\n",
    "            except ZeroDivisionError:\n",
    "                recalls.append(0)\n",
    "        precision = sum(precisions) / len(precisions)\n",
    "        recall = sum(recalls) / len(recalls)\n",
    "\n",
    "        print(f\"Precision@{cutoff}: {precision}\")\n",
    "        print(f\"Recall@{cutoff}: {recall}\")\n",
    "        return  precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize and Train The Model\n",
    "Now, we are ready to initialize and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Starting training...\n",
      "*** Epoch 1/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 61992.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 2/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 59647.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 3/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 62649.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 4/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 60484.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 5/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 60437.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 6/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 60724.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 7/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 59025.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 8/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 60908.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 9/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 61272.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 10/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 59605.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 11/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 54704.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 12/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 59709.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 13/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 59844.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 14/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 54050.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 15/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 60687.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 16/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 59268.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 17/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 58271.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 18/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 59257.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 19/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 60611.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 20/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 57361.42it/s]\n"
     ]
    }
   ],
   "source": [
    "f = 100\n",
    "lr = 0.001\n",
    "lmb = 0.1\n",
    "epochs = 20\n",
    "\n",
    "mf = MF(train_set, maps, f, relevance=4)\n",
    "mf.train(lr, lmb, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate The Model\n",
    "\n",
    "The evaluation is computed on Top-K recommendation lists (default K = 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation...\n",
      "Reading test set...\n",
      "Computing metrics...\n",
      "Precision@10: 0.058524590163934534\n",
      "Recall@10: 0.03103142768420843\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.058524590163934534, 0.03103142768420843)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build DP schema on dataset\n",
    "\n",
    "Before feeding our recommender, we preprocess the dataset by measuring noisy versions of some global effects. In detail we measure:\n",
    "* a differentially private version of the global average\n",
    "* a differentially private version of the item averages\n",
    "* a differentially private version of the user averages\n",
    "\n",
    "Finally, we clamp the resulting ratings\n",
    "\n",
    "This preprocessing is proven to allow deriving more accurate predictions when using the MF approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def privatize_global_effects(ratings, b_m, b_u, eps_global_avg, eps_item_avg, eps_user_avg, clamping):\n",
    "    min_rating = ratings['rating'].min()\n",
    "    max_rating = ratings['rating'].max()\n",
    "    delta_r = max_rating - min_rating\n",
    "\n",
    "    # Measure the noisy version\n",
    "\n",
    "    global_average_item = (ratings['rating'].sum() + np.random.laplace(scale=(delta_r / eps_global_avg))) / len(ratings)\n",
    "\n",
    "    item_sets = ratings.groupby('movieId')['rating']\n",
    "    i_avg = (item_sets.sum() + b_m * global_average_item + np.random.laplace(scale=(delta_r / eps_item_avg),\n",
    "                                                                             size=len(item_sets))) / (\n",
    "                        item_sets.count() + b_m)\n",
    "    i_avg = np.clip(i_avg, min_rating, max_rating)\n",
    "\n",
    "    merged = ratings.join(i_avg, on=['movieId'], lsuffix='_x', rsuffix='_y')\n",
    "\n",
    "    merged['rating'] = merged['rating_x'] - merged['rating_y']\n",
    "    merged = merged.drop(columns=['rating_x', 'rating_y'], axis=1)\n",
    "\n",
    "    global_average_user = (merged['rating'].sum() + np.random.laplace(scale=(delta_r / eps_global_avg))) / len(merged)\n",
    "\n",
    "    user_sets = merged.groupby('userId')['rating']\n",
    "    u_avg = (user_sets.sum() + b_u * global_average_user + np.random.laplace(scale=(delta_r / eps_user_avg))) / (\n",
    "                user_sets.count() + b_u)\n",
    "    u_avg = np.clip(u_avg, -2, 2)\n",
    "    # Values come from the implementation of this approach by Friedman et al., 2016\n",
    "\n",
    "    preprocessed_ratings = merged.join(u_avg, on=['userId'], lsuffix='_x', rsuffix='_y')\n",
    "\n",
    "    preprocessed_ratings['rating'] = preprocessed_ratings['rating_x'] - preprocessed_ratings['rating_y']\n",
    "    preprocessed_ratings = preprocessed_ratings.drop(columns=['rating_x', 'rating_y'], axis=1)\n",
    "    preprocessed_ratings['rating'] = np.clip(preprocessed_ratings['rating'], -clamping, clamping)\n",
    "\n",
    "    return preprocessed_ratings, i_avg, u_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "From Friedman et. al, 2016, having a eps privacy budget, we can split it with the following proportion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eps = 5\n",
    "eps_global_avg = 0.02 * eps\n",
    "eps_item_avg = 0.14 * eps\n",
    "eps_user_avg = 0.14 * eps\n",
    "# Overall, we used 0.3 of our eps for the preprocessing\n",
    "# The remaing 0.7 of eps is used for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's preprocess the data based on the protocol we analyzed so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "b_m = 5\n",
    "b_u = 5\n",
    "clamping = 1\n",
    "preproc_train_set, i_avg, u_avg = privatize_global_effects(train_set, b_m, b_u, eps_global_avg, eps_item_avg,\n",
    "                                                           eps_user_avg, clamping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's explore the first perturbation strategy, applied on the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Starting training...\n",
      "*** Epoch 1/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 45030.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 2/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 51567.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 3/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:02<00:00, 39849.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 4/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 51869.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 5/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 51220.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 6/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 55822.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 7/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 54738.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 8/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 55449.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 9/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 57106.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 10/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 50064.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 11/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 57276.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 12/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 52034.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 13/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 52827.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 14/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 57330.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 15/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 57377.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 16/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 57679.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 17/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 57225.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 18/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 56657.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 19/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 52393.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 20/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 57896.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation...\n",
      "Reading test set...\n",
      "Computing metrics...\n",
      "Precision@10: 0.020163934426229473\n",
      "Recall@10: 0.009735975249187529\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.020163934426229473, 0.009735975249187529)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def input_perturbation(ratings, clamping, eps):\n",
    "    # Range of the received ratings is [-clamping, clamping]\n",
    "    # In the input perturbation approach, each rating is perturbed in a way that maintains differential privacy\n",
    "    delta_r = 2 * clamping  # global sensitivity\n",
    "\n",
    "    # differential privacy\n",
    "    perturbed_ratings = ratings.copy()\n",
    "    perturbed_ratings['rating'] = np.clip(ratings['rating'] + np.random.laplace(scale=(delta_r / eps), size=len(ratings)),\n",
    "                                -clamping, clamping)\n",
    "\n",
    "    return perturbed_ratings\n",
    "\n",
    "train_set_perturbed = input_perturbation(train_set, 1, 0.7 * eps)\n",
    "mf_dp_data = MF(train_set_perturbed, maps, f, relevance=4, i_avg=i_avg, u_avg=u_avg)\n",
    "mf_dp_data.train(lr, lmb, epochs)\n",
    "mf_dp_data.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the second approach, with the differential privacy applied to the SGD algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "*** Epoch 1/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 46285.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 2/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 47689.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 3/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 43950.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 4/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 46996.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 5/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 42469.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 6/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 47783.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 7/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 46101.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 8/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80419/80419 [00:01<00:00, 44706.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 9/20 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 137/80419 [00:00<00:03, 26357.49it/s]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/claudio/PycharmProjects/RecSysPrivacyTutorial/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1cf3ab10aa07>\", line 2, in <module>\n",
      "    mf_dp_sgd.train_laplace_dp(lr, lmb, epochs, 0.7 * eps)\n",
      "  File \"<ipython-input-4-4d0bace1df81>\", line 75, in train_laplace_dp\n",
      "    self.b_u[self.dataset['userId'][i]] += lr * (err - beta * self.b_u[self.dataset['userId'][i]])\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/claudio/PycharmProjects/RecSysPrivacyTutorial/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/claudio/PycharmProjects/RecSysPrivacyTutorial/venv/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/claudio/PycharmProjects/RecSysPrivacyTutorial/venv/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/claudio/PycharmProjects/RecSysPrivacyTutorial/venv/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 428, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[0;32m<ipython-input-12-1cf3ab10aa07>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mmf_dp_sgd\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mMF\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_set\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmaps\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrelevance\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi_avg\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mi_avg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mu_avg\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mu_avg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mmf_dp_sgd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_laplace_dp\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlmb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.7\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0meps\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mmf_dp_sgd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_set\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-4-4d0bace1df81>\u001B[0m in \u001B[0;36mtrain_laplace_dp\u001B[0;34m(self, lr, beta, epochs, eps, err_max)\u001B[0m\n\u001B[1;32m     74\u001B[0m                 \u001B[0;31m# Update biases\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 75\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mb_u\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'userId'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mlr\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0merr\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mbeta\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mb_u\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'userId'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     76\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mb_i\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'itemId'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mlr\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0merr\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mbeta\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mb_i\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'itemId'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m~/PycharmProjects/RecSysPrivacyTutorial/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2043\u001B[0m                         \u001B[0;31m# in the engines. This should return a list of strings.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2044\u001B[0;31m                         \u001B[0mstb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2045\u001B[0m                     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/RecSysPrivacyTutorial/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2045\u001B[0m                     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2046\u001B[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001B[0;32m-> 2047\u001B[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001B[0m\u001B[1;32m   2048\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2049\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_showtraceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/RecSysPrivacyTutorial/venv/lib/python3.6/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1434\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1435\u001B[0m         return FormattedTB.structured_traceback(\n\u001B[0;32m-> 1436\u001B[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001B[0m\u001B[1;32m   1437\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1438\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/RecSysPrivacyTutorial/venv/lib/python3.6/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1334\u001B[0m             \u001B[0;31m# Verbose modes need a full traceback\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1335\u001B[0m             return VerboseTB.structured_traceback(\n\u001B[0;32m-> 1336\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb_offset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnumber_of_lines_of_context\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1337\u001B[0m             )\n\u001B[1;32m   1338\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mmode\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'Minimal'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/RecSysPrivacyTutorial/venv/lib/python3.6/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1191\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1192\u001B[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001B[0;32m-> 1193\u001B[0;31m                                                                tb_offset)\n\u001B[0m\u001B[1;32m   1194\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1195\u001B[0m         \u001B[0mcolors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mColors\u001B[0m  \u001B[0;31m# just a shorthand + quicker name lookup\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/RecSysPrivacyTutorial/venv/lib/python3.6/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mformat_exception_as_a_whole\u001B[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[1;32m   1148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1149\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1150\u001B[0;31m         \u001B[0mlast_unique\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfind_recursion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0morig_etype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1151\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1152\u001B[0m         \u001B[0mframes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat_records\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlast_unique\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/RecSysPrivacyTutorial/venv/lib/python3.6/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mfind_recursion\u001B[0;34m(etype, value, records)\u001B[0m\n\u001B[1;32m    449\u001B[0m     \u001B[0;31m# first frame (from in to out) that looks different.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    450\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_recursion_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 451\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    452\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    453\u001B[0m     \u001B[0;31m# Select filename, lineno, func_name to track frames with\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "mf_dp_sgd = MF(train_set, maps, f, relevance=4, i_avg=i_avg, u_avg=u_avg)\n",
    "mf_dp_sgd.train_laplace_dp(lr, lmb, epochs, 0.7 * eps)\n",
    "mf_dp_sgd.evaluate(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eps_valuse = [0.2, 1, 5, 10]\n",
    "results = {}\n",
    "for eps in eps_valuse:\n",
    "    print(f\"*** start eps {eps} ***\")\n",
    "    eps_global_avg = 0.02 * eps\n",
    "    eps_item_avg = 0.14 * eps\n",
    "    eps_user_avg = 0.14 * eps\n",
    "    b_m = 5\n",
    "    b_u = 5\n",
    "    clamping = 1\n",
    "    preproc_train_set, i_avg, u_avg = privatize_global_effects(train_set, b_m, b_u, eps_global_avg, eps_item_avg,\n",
    "                                                               eps_user_avg, clamping)\n",
    "    train_set_perturbed = input_perturbation(train_set, 1, 0.7 * eps)\n",
    "    mf_dp_data = MF(train_set_perturbed, maps, f, relevance=4, i_avg=i_avg, u_avg=u_avg)\n",
    "    mf_dp_data.train(lr, lmb, epochs)\n",
    "    p_d, r_d = mf_dp_data.evaluate(test_set)\n",
    "\n",
    "    mf_dp_sgd = MF(train_set, maps, f, relevance=4, i_avg=i_avg, u_avg=u_avg)\n",
    "    mf_dp_sgd.train_laplace_dp(lr, lmb, epochs, 0.7 * eps)\n",
    "    p_m, r_m = mf_dp_sgd.evaluate(test_set)\n",
    "\n",
    "    results.update({eps: (p_d, r_d, p_m, r_m)})\n",
    "    print(f\"*** end eps {eps} ***\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(results[0.2])):\n",
    "    plt.plot(results.keys(), [v[i] for k, v in results.items()])\n",
    "\n",
    "plt.title('Precision across eps')\n",
    "plt.xlabel('eps')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}