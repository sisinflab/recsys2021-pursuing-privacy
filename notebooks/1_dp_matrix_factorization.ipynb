{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook, we will learn to implement a simple differentially private matrix factorization from scratch, with three different strategies:\n",
    "* input perturbation with Laplacian mechanism\n",
    "* gradient perturbation with Laplacian mechanism\n",
    "* (unbounded) gradient perturbation with Gaussian mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Import packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!conda install pandas tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import io\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import create_maps, splitting\n",
    "\n",
    "np.random.seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Load Data\n",
    "\n",
    "First, we download the latest version of the Movielens Small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "url = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "print(f\"Getting Movielens Small from : {url} ...\")\n",
    "response = requests.get(url)\n",
    "\n",
    "ml_ratings = []\n",
    "\n",
    "print(\"Extracting ratings...\")\n",
    "with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
    "    for line in zip_ref.open(\"ml-latest-small/ratings.csv\"):\n",
    "        ml_ratings.append(str(line, \"utf-8\"))\n",
    "\n",
    "print(\"Printing ratings to data/movielens/ ...\")\n",
    "os.makedirs(\"data/movielens\", exist_ok=True)\n",
    "with open(\"data/movielens/dataset.csv\", \"w\") as f:\n",
    "    f.writelines(ml_ratings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataframe_ml_small = pd.read_csv('data/movielens/dataset.csv')\n",
    "\n",
    "train_set, test_set = splitting(dataframe_ml_small)\n",
    "train_set = train_set.loc[:, ['userId', 'movieId', 'rating']]\n",
    "test_set = test_set.loc[:, ['userId', 'movieId', 'rating']]\n",
    "maps = create_maps(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "\n",
    "Create MF class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MF:\n",
    "    def __init__(self, dataset, maps, n_factors, relevance=3.5, i_avg=None, u_avg=None):\n",
    "        \"\"\"\n",
    "        :param dataset: interaction dataset should be a Pandas dataframe with three columns for user, item, and rating\n",
    "        :param n_factors:\n",
    "        \"\"\"\n",
    "        print(\"Building model...\")\n",
    "        self.ext2int_user_map, self.int2ext_user_map, self.ext2int_item_map, self.int2ext_item_map = maps\n",
    "        self.dataset = self.format_dataset(dataset)\n",
    "        self.rated_items = {\n",
    "            self.ext2int_user_map[u]: dataset[(dataset.iloc[:, 0] == u) & (dataset.iloc[:, 2] >= relevance)].iloc[:,\n",
    "                                      1].map(self.ext2int_item_map).astype(int).to_list() for u in\n",
    "            self.ext2int_user_map}\n",
    "        n_users = len(self.ext2int_user_map)\n",
    "        n_items = len(self.ext2int_item_map)\n",
    "        self.n_interactions = len(dataset)\n",
    "        self.delta_ratings = dataset.iloc[:, 2].max() - dataset.iloc[:, 2].min()\n",
    "        self.p = np.random.normal(size=(n_users, n_factors), scale=1./n_factors, loc=0)\n",
    "        self.q = np.random.normal(size=(n_items, n_factors), scale=1./n_factors, loc=0)\n",
    "\n",
    "        self.b_u = np.zeros(n_users)\n",
    "        self.b_i = np.zeros(n_items)\n",
    "        self.b = np.mean(dataset['rating'])\n",
    "\n",
    "        self.i_avg = None\n",
    "        self.u_avg = None\n",
    "        if i_avg is not None and u_avg is not None:\n",
    "            self.i_avg = i_avg.to_numpy()\n",
    "            self.u_avg = u_avg.to_numpy()\n",
    "\n",
    "        def format_dataset(self, df):\n",
    "            dataset = {}\n",
    "            dataset['userId'] = df.iloc[:, 0].map(self.ext2int_user_map).to_dict()\n",
    "            dataset['itemId'] = df.iloc[:, 1].map(self.ext2int_item_map).to_dict()\n",
    "            dataset['rating'] = df.iloc[:, 2].to_dict()\n",
    "            return dataset\n",
    "\n",
    "    def train(self, lr, beta, epochs):\n",
    "        print(\"Starting training...\")\n",
    "        for e in range(epochs):\n",
    "            print(f\"*** Epoch {e + 1}/{epochs} ***\")\n",
    "            for i in tqdm(range(self.n_interactions)):\n",
    "                p_u = self.p[self.dataset['userId'][i]]\n",
    "                q_i = self.q[self.dataset['itemId'][i]]\n",
    "                pred = self.b + self.b_u[self.dataset['userId'][i]] + self.b_i[self.dataset['itemId'][i]] + p_u.dot(q_i)\n",
    "                err = self.dataset['rating'][i] - pred\n",
    "\n",
    "                # Update biases\n",
    "                self.b_u[self.dataset['userId'][i]] += lr * (err - beta * self.b_u[self.dataset['userId'][i]])\n",
    "                self.b_i[self.dataset['itemId'][i]] += lr * (err - beta * self.b_i[self.dataset['itemId'][i]])\n",
    "\n",
    "                self.p[self.dataset['userId'][i]] = p_u + lr * (err * q_i - beta * p_u)\n",
    "                self.q[self.dataset['itemId'][i]] = q_i + lr * (err * p_u - beta * q_i)\n",
    "\n",
    "    def train_laplace_dp(self, lr, beta, epochs, eps, err_max=None):\n",
    "        for e in range(epochs):\n",
    "            print(f\"*** Epoch {e + 1}/{epochs} ***\")\n",
    "            for i in tqdm(range(self.n_interactions)):\n",
    "                p_u = self.p[self.dataset['userId'][i]]\n",
    "                q_i = self.q[self.dataset['itemId'][i]]\n",
    "                pred = self.b + self.b_u[self.dataset['userId'][i]] + self.b_i[self.dataset['itemId'][i]] + p_u.dot(q_i)\n",
    "                err = self.dataset['rating'][i] - pred + np.random.laplace(scale=(epochs * self.delta_ratings / eps))\n",
    "                if err_max:\n",
    "                    err = np.clip(err, -err_max, err_max)\n",
    "\n",
    "                # Update biases\n",
    "                self.b_u[self.dataset['userId'][i]] += lr * (err - beta * self.b_u[self.dataset['userId'][i]])\n",
    "                self.b_i[self.dataset['itemId'][i]] += lr * (err - beta * self.b_i[self.dataset['itemId'][i]])\n",
    "\n",
    "                self.p[self.dataset['userId'][i]] = p_u + lr * (err * q_i)\n",
    "                self.q[self.dataset['itemId'][i]] = q_i + lr * (err * p_u)\n",
    "\n",
    "    def train_gaussian_unbounded_dp(self, lr, epochs, eps, delta, err_max=None):\n",
    "        for e in range(epochs):\n",
    "            print(f\"*** Epoch {e + 1}/{epochs} ***\")\n",
    "            for i in tqdm(range(self.n_interactions)):\n",
    "                p_u = self.p[self.dataset['userId'][i]]\n",
    "                q_i = self.q[self.dataset['itemId'][i]]\n",
    "                pred = p_u.dot(q_i)\n",
    "                err = np.clip(self.dataset['rating'][i] - pred, err_max)\n",
    "                self.p[self.dataset['userId'][i]] = p_u + lr * (err * q_i)\n",
    "                self.q[self.dataset['itemId'][i]] = q_i + lr * (err * p_u)\n",
    "            for u in self.int2ext_user_map:\n",
    "                2 * s_p * epochs * np.sqrt(2 * np.log(2 / delta)) / eps\n",
    "                # TODO: Terminare\n",
    "\n",
    "    def evaluate(self, test=None, cutoff=10, relevance=0.5):\n",
    "        print(\"Starting evaluation...\")\n",
    "        if self.i_avg is not None and self.u_avg is not None:\n",
    "            prediction = self.b + self.b_u[:, np.newaxis] + self.b_i[np.newaxis, :] + \\\n",
    "                         (np.dot(self.p, self.q.T).T + self.i_avg[:, None]).T + self.u_avg[:, None]\n",
    "        else:\n",
    "            prediction = self.b + self.b_u[:, np.newaxis] + self.b_i[np.newaxis, :] + np.dot(self.p, self.q.T)\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        print(\"Reading test set...\")\n",
    "        relevant_items_test = {\n",
    "            self.ext2int_user_map[u]: set(test[(test.iloc[:, 0] == u) & (test.iloc[:, 2] >= relevance)].iloc[:, 1].map(\n",
    "                self.ext2int_item_map).dropna().astype(int).to_list()) for u in self.ext2int_user_map}\n",
    "        print(\"Computing metrics...\")\n",
    "        for u in self.int2ext_user_map:\n",
    "            prediction[u, self.rated_items[u]] = - np.inf\n",
    "            unordered_top_k = np.argpartition(prediction[u], -cutoff)[-cutoff:]\n",
    "            top_k = unordered_top_k[np.argsort(prediction[u][unordered_top_k])][::-1]\n",
    "            n_rel_and_rec_k = sum(i in relevant_items_test[u] for i in top_k)\n",
    "            precisions.append(n_rel_and_rec_k / cutoff)\n",
    "            try:\n",
    "                recalls.append(n_rel_and_rec_k / len(relevant_items_test[u]))\n",
    "            except ZeroDivisionError:\n",
    "                recalls.append(0)\n",
    "        precision = sum(precisions) / len(precisions)\n",
    "        recall = sum(recalls) / len(recalls)\n",
    "\n",
    "        print(f\"Precision@{cutoff}: {precision}\")\n",
    "        print(f\"Recall@{cutoff}: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Initialize and Train The Model\n",
    "Now, we are ready to initialize and train the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "f = 100\n",
    "lr = 0.001\n",
    "beta = 0.1\n",
    "epochs = 20\n",
    "\n",
    "mf = MF(train_set, maps, f, relevance=4)\n",
    "mf.train(lr, beta, epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluate The Model\n",
    "\n",
    "The evaluation is computed on Top-K recommendation lists (default K = 10)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mf.evaluate(test_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build DP schema on dataset\n",
    "\n",
    "Before feeding our recommender, we preprocess the dataset by measuring noisy versions of some global effects. In detail we measure:\n",
    "* a differentially private version of the global average\n",
    "* a differentially private version of the item averages\n",
    "* a differentially private version of the user averages\n",
    "\n",
    "Finally, we clamp the resulting ratings\n",
    "\n",
    "This preprocessing is proven to allow deriving more accurate predictions when using the MF approach"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def privatize_global_effects(ratings, b_m, b_u, eps_global_avg, eps_item_avg, eps_user_avg, clamping):\n",
    "    min_rating = ratings['rating'].min()\n",
    "    max_rating = ratings['rating'].max()\n",
    "    delta_r = max_rating - min_rating\n",
    "\n",
    "    # Measure the noisy version\n",
    "\n",
    "    global_average_item = (ratings['rating'].sum() + np.random.laplace(scale=(delta_r / eps_global_avg))) / len(ratings)\n",
    "\n",
    "    item_sets = ratings.groupby('movieId')['rating']\n",
    "    i_avg = (item_sets.sum() + b_m * global_average_item + np.random.laplace(scale=(delta_r / eps_item_avg),\n",
    "                                                                             size=len(item_sets))) / (\n",
    "                        item_sets.count() + b_m)\n",
    "    i_avg = np.clip(i_avg, min_rating, max_rating)\n",
    "\n",
    "    merged = ratings.join(i_avg, on=['movieId'], lsuffix='_x', rsuffix='_y')\n",
    "\n",
    "    merged['rating'] = merged['rating_x'] - merged['rating_y']\n",
    "    merged = merged.drop(columns=['rating_x', 'rating_y'], axis=1)\n",
    "\n",
    "    global_average_user = (merged['rating'].sum() + np.random.laplace(scale=(delta_r / eps_global_avg))) / len(merged)\n",
    "\n",
    "    user_sets = merged.groupby('userId')['rating']\n",
    "    u_avg = (user_sets.sum() + b_u * global_average_user + np.random.laplace(scale=(delta_r / eps_user_avg))) / (\n",
    "                user_sets.count() + b_u)\n",
    "    u_avg = np.clip(u_avg, -2, 2)  # Valore dal paper\n",
    "\n",
    "    preprocessed_ratings = merged.join(u_avg, on=['userId'], lsuffix='_x', rsuffix='_y')\n",
    "\n",
    "    preprocessed_ratings['rating'] = preprocessed_ratings['rating_x'] - preprocessed_ratings['rating_y']\n",
    "    preprocessed_ratings = preprocessed_ratings.drop(columns=['rating_x', 'rating_y'], axis=1)\n",
    "    preprocessed_ratings['rating'] = np.clip(preprocessed_ratings['rating'], -clamping, clamping)\n",
    "\n",
    "    return preprocessed_ratings, i_avg, u_avg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train model with preprocessed data within DP on train schema"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b_m = 1\n",
    "b_u = 1\n",
    "eps_global_avg = 1\n",
    "eps_item_avg = 1\n",
    "eps_user_avg = 1\n",
    "clamping = 1\n",
    "\n",
    "preproc_train_set, i_avg, u_avg = privatize_global_effects(train_set, b_m, b_u, eps_global_avg, eps_item_avg,\n",
    "                                                           eps_user_avg, clamping)\n",
    "\n",
    "mf_dp_data = MF(train_set, maps, f, relevance=4, i_avg=i_avg, u_avg=u_avg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluate the performance with this DP schema"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mf_dp_data.train(lr, beta, epochs)\n",
    "mf_dp_data.evaluate(test_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train model with DP schema during training phase"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mf_dp_train = MF(train_set, maps, f, relevance=4, i_avg=i_avg, u_avg=u_avg)\n",
    "\n",
    "mf_dp_data.train_laplace_dp(lr, beta, epochs, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluate the performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mf_dp_data.evaluate(test_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}